# -*- coding: utf-8 -*-
"""Final_Proj.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D4euvw_QbMJ0lvGaTpDnneecgEjxBoEt
"""

from google.colab import drive
drive.mount('/content/drive')

cd /content/drive/MyDrive/

ls

cd FinalProject_DM/

pwd

# Importing the important libraries

import numpy as np
import random
import pandas as pd

from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler , MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report , confusion_matrix, accuracy_score, f1_score

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier 
from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV


import warnings
warnings.filterwarnings('ignore')

# Loading the dataset

df = pd.read_csv('heart.csv')
df.head()

print(df.shape)
print(df["HeartDisease"].value_counts())

df.isnull().sum()

df.describe()

df.info()

# Seperating the dependent and the independent columns

X = df.drop("HeartDisease" , axis = 1)
y = df['HeartDisease']

# Seperating the numerical and the categorical columns

cat_cols = list(df.select_dtypes(include=['object']).columns)
num_cols = []

for i in list(X.columns):
  if i not in cat_cols:
    num_cols.append(i)

print(cat_cols , num_cols)

normal_cols = ["Age","MaxHR","RestingBP"]
for col in normal_cols:
    mean = np.mean(df[col])
    std = np.std(df[col])
    lower_range = mean - (3*std)
    upper_range = mean + (3*std)
    df[col] = np.where(((df[col] < lower_range) | (df[col] > upper_range))
                            ,random.randint(int(lower_range),int(upper_range)),df[col])

IQR = np.percentile(df["Cholesterol"],75) - np.percentile(df["Cholesterol"],25)
lower_bound = np.percentile(df["Cholesterol"],25) - 1.5 * IQR
upper_bound = np.percentile(df["Cholesterol"],75) + 1.5 * IQR
median_cholesterol = np.median(df["Cholesterol"])

df["Cholesterol"] = np.where(((df["Cholesterol"] > upper_bound) | (df["Cholesterol"] < lower_bound)) 
                                 ,random.randint(int(np.percentile(df["Cholesterol"],25)),
                                                 int(np.percentile(df["Cholesterol"],75))),df["Cholesterol"])

# Seperating the train and test dataset
x_train,x_test,y_train,y_test = train_test_split(X,y,stratify = y , random_state=42,test_size=0.2)

x_train[:3]

# Standardadising the features of training and testing dataset

scaler = StandardScaler()
scaler.fit(X[num_cols])
X[num_cols] = scaler.transform(X[num_cols])

X = pd.get_dummies(data = X , drop_first=True)

# Seperating the train and test dataset
x_train,x_test,y_train,y_test = train_test_split(X,y,stratify = y , random_state=42,test_size=0.2)

x_train[:3]

"""# KNN Algorithm"""

knn = KNeighborsClassifier(n_neighbors=7)
knn.fit(x_train,y_train)
y_pred_knn = knn.predict(x_test)

print(knn.score(x_test,y_test))
print(classification_report(y_test,y_pred_knn))
print(confusion_matrix(y_test,y_pred_knn))
#compare with table

"""# SVM Algorithm"""

from sklearn.svm import SVC
classifier = SVC(kernel='rbf', random_state=27)
classifier.fit(x_train, y_train)

y_pred_svm = classifier.predict(x_test)

print(classifier.score(x_test,y_test))
print(classification_report(y_test, y_pred_svm))
print(confusion_matrix(y_test,y_pred_svm))

"""# Random Forest Algorithm"""

randomforest = RandomForestClassifier()
randomforest.fit(x_train,y_train)
y_pred_rf = randomforest.predict(x_test)

print('Train Accuracy %s' % round(accuracy_score(y_test, y_pred_rf),2))
print('Train F1-score %s' % f1_score(y_test, y_pred_rf, average=None))
print(classification_report(y_test, y_pred_rf))
print("Confusion Matrix:\n",confusion_matrix(y_test, y_pred_rf))

knn_acc = []
knn_tss = []
knn_prec = []
knn_tn = []
knn_tp = []
knn_fn = []
knn_fp = []

svm_acc = []
svm_tss = []
svm_prec = []
svm_tn = []
svm_tp = []
svm_fn = []
svm_fp = []

randmf_acc = []
randmf_tss = []
randmf_prec = []
randmf_tn = []
randmf_tp = []
randmf_fn = []
randmf_fp = []

for i in range(0,11):

  x_train,x_test,y_train,y_test = train_test_split(X,y,stratify = y , random_state=42,test_size=0.3)
  
  ## Running KNN Algorithm
  knn.fit(x_train,y_train)
  y_pred_knn = knn.predict(x_test)

  tn, fp, fn, tp = confusion_matrix(y_test, y_pred_knn).ravel()
  knn_tn.append(tn)
  knn_tp.append(fp)
  knn_fn.append(fn)
  knn_fp.append(tp)

  acck = (tp + tn) / (tn + fp + fn + tp)
  tss = (tp / (tp - fn)) - (fp / (fp + tn))
  precision = tp / (tp + fp)

  knn_acc.append(acck)
  knn_tss.append(tss)
  knn_prec.append(precision)

  ## Running Random Forest Algorithm
  randomforest.fit(x_train,y_train)
  y_pred_rf = randomforest.predict(x_test)

  tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()
  randmf_tn.append(tn)
  randmf_tp.append(fp)
  randmf_fn.append(fn)
  randmf_fp.append(tp)

  accrf = (tp + tn) / (tn + fp + fn + tp)
  tss = (tp / (tp - fn)) - (fp / (fp + tn))
  precision = tp / (tp + fp)

  randmf_acc.append(accrf)
  randmf_tss.append(tss)
  randmf_prec.append(precision)

  ## Running SVM Algorithm
  classifier.fit(x_train, y_train)
  y_pred_svm = classifier.predict(x_test)

  tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()
  svm_tn.append(tn)
  svm_tp.append(fp)
  svm_fn.append(fn)
  svm_fp.append(tp)

  accs = (tp + tn) / (tn + fp + fn + tp)
  tss = (tp / (tp - fn)) - (fp / (fp + tn))
  precision = tp / (tp + fp)

  svm_acc.append(accs)
  svm_tss.append(tss)
  svm_prec.append(precision)

## Average: 
avg_knn_acc = sum(knn_acc) / len(knn_acc)
avg_knn_tss = sum(knn_tss) / len(knn_tss)
avg_knn_prec = sum(knn_prec) / len(knn_prec)
avg_knn_tn = sum(knn_tn) / len(knn_tn)
avg_knn_tp = sum(knn_tp) / len(knn_tp)
avg_knn_fn = sum(knn_fn) / len(knn_fn)
avg_knn_fp = sum(knn_fp) / len(knn_fp)

## Average: 
avg_svm_acc = sum(svm_acc) / len(svm_acc)
avg_svm_tss = sum(svm_tss) / len(svm_tss)
avg_svm_prec = sum(svm_prec) / len(svm_prec)
avg_svm_tn = sum(svm_tn) / len(svm_tn)
avg_svm_tp = sum(svm_tp) / len(svm_tp)
avg_svm_fn = sum(svm_fn) / len(svm_fn)
avg_svm_fp = sum(svm_fp) / len(svm_fp)

## Average: 
avg_randmf_acc = sum(randmf_acc) / len(randmf_acc)
avg_randmf_tss = sum(randmf_tss) / len(randmf_tss)
avg_randmf_prec = sum(randmf_prec) / len(randmf_prec)
avg_randmf_tn = sum(randmf_tn) / len(randmf_tn)
avg_randmf_tp = sum(randmf_tp) / len(randmf_tp)
avg_randmf_fn = sum(randmf_fn) / len(randmf_fn)
avg_randmf_fp = sum(randmf_fp) / len(randmf_fp)

table_cols = {'Algorithm' : ['KNN' , 'SVM' , 'Random Forest'] , 'TP' : [avg_knn_tp , avg_svm_tp , avg_randmf_tp] , 'FP' : [avg_knn_fp, avg_svm_fp, avg_randmf_fp] , 'FN' : [avg_knn_fn, avg_svm_fn, avg_randmf_fn] , 'TN' : [avg_knn_tn, avg_svm_tn, avg_randmf_tn] , 'ACC' : [avg_knn_acc, avg_svm_acc, avg_randmf_acc], 'TSS' : [avg_knn_tss , avg_svm_tss, avg_randmf_tss] , 'Precision' : [avg_knn_prec, avg_svm_prec, avg_randmf_prec]}

table_cols1 = pd.DataFrame.from_dict(table_cols)

table_cols1

